{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nous ferons ici une analyse économétrique des données comme vu dans les cours de l'ensae. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='Romain_Scrapping/offres_emploi_concatene_cleaned.csv'\n",
    "\n",
    "# Nombre attendu de colonnes\n",
    "expected_columns = 11\n",
    "\n",
    "# Fonction personnalisée pour lire le fichier\n",
    "def filter_csv(file_path, delimiter=','):\n",
    "    with open(file_path, 'r') as file:\n",
    "        filtered_rows = []\n",
    "        for line in file:\n",
    "            row = line.strip().split(delimiter)\n",
    "            if len(row) == expected_columns:\n",
    "                filtered_rows.append(row)\n",
    "    return pd.DataFrame(filtered_rows)\n",
    "\n",
    "# Chargement et affichage des données filtrées\n",
    "data = filter_csv(file_path)\n",
    "\n",
    "#Nomer les colonnes\n",
    "data.columns = data.iloc[0]\n",
    "data = data.drop(0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression sur les études et l'experiance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp_etude = data[['salaire_annuel', 'etude_requise' , 'experience_requise']]\n",
    "\n",
    "data_exp_etude['salaire_annuel'] = pd.to_numeric(data_exp_etude['salaire_annuel'], errors='coerce')\n",
    "data_exp_etude['etude_requise'] = pd.to_numeric(data_exp_etude['etude_requise'], errors='coerce')\n",
    "data_exp_etude['experience_requise'] = pd.to_numeric(data_exp_etude['experience_requise'], errors='coerce')\n",
    "\n",
    "# Supprimer les lignes contenant des valeurs manquantes\n",
    "data_exp_etude = data_exp_etude.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         salaire_annuel   R-squared:                       0.352\n",
      "Model:                            OLS   Adj. R-squared:                  0.352\n",
      "Method:                 Least Squares   F-statistic:                     3092.\n",
      "Date:                Sat, 28 Dec 2024   Prob (F-statistic):               0.00\n",
      "Time:                        19:46:03   Log-Likelihood:            -1.1969e+05\n",
      "No. Observations:               11371   AIC:                         2.394e+05\n",
      "Df Residuals:                   11368   BIC:                         2.394e+05\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const               1.461e+04    262.116     55.756      0.000    1.41e+04    1.51e+04\n",
      "etude_requise       2644.6868     50.561     52.307      0.000    2545.579    2743.794\n",
      "experience_requise   160.5902      3.820     42.043      0.000     153.103     168.077\n",
      "==============================================================================\n",
      "Omnibus:                     6589.791   Durbin-Watson:                   1.556\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           265458.334\n",
      "Skew:                           2.150   Prob(JB):                         0.00\n",
      "Kurtosis:                      26.276   Cond. No.                         91.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X = data_exp_etude[['etude_requise' , 'experience_requise']]\n",
    "y = data_exp_etude[['salaire_annuel']]\n",
    "\n",
    "# Initialisation et entraînement du modèle\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "X_with_const = sm.add_constant(X)  # Ajout de l'interception\n",
    "model_stats = sm.OLS(y, X_with_const)  # Création du modèle\n",
    "results = model_stats.fit()  # Ajustement du modèle\n",
    "\n",
    "# Résumé détaillé\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats de la régression montrent que le niveau d'études requis et l'expérience exigée ont un impact significatif sur le salaire annuel. Le modèle explique 35,2 % de la variance du salaire, avec des coefficients positifs pour les deux variables : chaque niveau d'études supplémentaire augmente le salaire de 2 644,69 €, et chaque année d'expérience ajoutée augmente le salaire de 160,59 €. Les tests statistiques montrent que ces effets sont statistiquement significatifs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression général"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = data[['salaire_annuel', 'etude_requise' , 'experience_requise', 'source','departement','contrat','secteur_activite']]\n",
    "\n",
    "data_reg['salaire_annuel'] = pd.to_numeric(data_reg['salaire_annuel'], errors='coerce')\n",
    "data_reg['etude_requise'] = pd.to_numeric(data_reg['etude_requise'], errors='coerce')\n",
    "data_reg['experience_requise'] = pd.to_numeric(data_reg['experience_requise'], errors='coerce')\n",
    "\n",
    "data_reg = pd.get_dummies(data_reg, columns=['source','departement','contrat','secteur_activite'], dtype=int)\n",
    "# Supprimer les lignes contenant des valeurs manquantes\n",
    "data_reg= data_reg.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data_reg.columns.tolist()\n",
    "cols.remove('salaire_annuel')\n",
    "\n",
    "X = data_reg[cols]\n",
    "y = data_reg[['salaire_annuel']]\n",
    "\n",
    "# Initialisation et entraînement du modèle\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "X_with_const = sm.add_constant(X)  # Ajout de l'interception\n",
    "model_stats = sm.OLS(y, X_with_const)  # Création du modèle\n",
    "results = model_stats.fit()  # Ajustement du modèle\n",
    "\n",
    "with open(\"OLS_results_summary.txt\", \"w\") as file:\n",
    "    file.write(results.summary().as_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie prédictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients du modèle : [ 2.03204618e+03  1.42168892e+02 -6.58777873e+02 -2.23413370e+03\n",
      "  5.86055422e+03 -3.81195670e+03 -6.48504260e+02  1.19967901e+03\n",
      "  5.96189107e+03 -1.76880007e+03 -3.71715875e+02  7.69387789e+02\n",
      "  2.02123726e+03 -0.00000000e+00  1.04760156e+03  1.06687519e+03\n",
      " -7.26058851e+02  1.32831533e+03  0.00000000e+00 -8.68580430e+02\n",
      "  6.49110648e+03 -1.75418032e+03 -1.73026911e+03  1.80583465e+03\n",
      "  7.40513513e+02  1.31583880e+03 -5.36795350e+02 -2.31177769e+03\n",
      "  1.82869889e+02 -1.12204910e+03 -9.95745093e+02  9.37776115e+01\n",
      "  0.00000000e+00 -1.43310329e+02  1.18743547e+02 -1.60761428e+03\n",
      " -1.06313209e+03  6.15037152e+02  4.19960695e+02 -2.43238107e+02\n",
      "  1.00946514e+02 -1.90166416e+03 -9.05823500e+02 -9.00993425e+03\n",
      " -1.73194751e+03 -8.36691456e+00  1.15345480e+03  5.15125452e+02\n",
      "  1.83639432e+02  3.16479863e+02 -8.29331936e+02  2.43171402e+03\n",
      "  9.69043136e+02 -4.30268044e+02  5.17499384e+03  1.76385305e+03\n",
      "  2.61702587e+02  2.36906807e+02 -1.82665124e+03  4.97543427e+02\n",
      " -2.42370513e+02  3.99446852e+01 -1.92423910e+03 -1.50049959e+02\n",
      " -6.93096698e+01  2.15463948e+02  1.19381897e+03 -6.29464802e+02\n",
      " -3.38940634e+02 -1.53797771e+03 -4.17837366e+02 -3.28421067e+02\n",
      "  2.65564775e+02  7.64066527e+02 -0.00000000e+00 -1.08026255e+03\n",
      " -9.61518324e+02  3.79349104e+02 -1.41700921e+03 -1.71794946e+02\n",
      " -4.85561471e+02  1.14847969e+03  1.72157870e+02 -7.34808245e+02\n",
      " -1.37628863e+03  2.47944940e+02  1.02444792e+03  1.85485752e+03\n",
      " -1.16163096e+03 -8.16968323e-01 -1.29132344e+03  4.85441099e+02\n",
      "  1.53613010e+03  3.48802551e+03 -3.80928470e+02  7.75184093e+02\n",
      "  2.38831427e+03  1.82638660e+03  0.00000000e+00 -1.08492811e+03\n",
      " -6.96526389e+02 -7.95736130e+02  3.26864382e+02 -1.65846715e+03\n",
      " -1.89660470e+03 -9.94634154e+02 -1.11675805e+03 -6.49251176e+02\n",
      "  2.17195141e+03  0.00000000e+00  4.92179890e+02  1.42684713e+03\n",
      "  3.04156654e+03  1.02836549e+03  1.96967506e+03  1.01163157e+03\n",
      "  0.00000000e+00 -6.66290377e+02  8.79720218e+04  1.23069958e+03\n",
      " -1.16312963e+03  0.00000000e+00 -2.29450231e+03  2.20046918e+03\n",
      "  2.72052014e+03  1.71234947e+04  0.00000000e+00  7.79716056e+02\n",
      "  0.00000000e+00  0.00000000e+00  2.16882038e+03 -5.53576801e+01\n",
      " -3.49992070e+03 -9.84711481e+03  3.22753475e+02 -8.68768330e+03\n",
      "  5.37637313e+03 -6.85491853e+03  5.66350412e+03 -4.31349565e+03\n",
      "  0.00000000e+00  6.58552214e+03  3.23508257e+03  4.27295458e+03\n",
      " -1.11138360e+03  1.64916349e+03  6.49659985e+03  5.27376881e+03\n",
      "  2.43528522e+03  2.20754063e+03  1.41850734e+03  3.71497425e+03\n",
      "  6.47123393e+03 -2.88171843e+03  1.24938020e+03  2.73388059e+03\n",
      "  8.85624132e+02 -6.45420659e+02  3.33826384e+02 -3.26984715e+03\n",
      " -0.00000000e+00 -4.06281876e+03  1.01728173e+02 -3.64434999e+02\n",
      " -2.49016579e+02  8.93955864e+02  5.07827723e+01  9.56993315e+01\n",
      "  7.23731903e+03 -1.18480008e+03  1.30491948e+03  1.22442309e+04\n",
      " -9.40533226e+02 -0.00000000e+00  1.26748937e+03 -6.75469909e+03\n",
      "  0.00000000e+00  2.69530516e+03 -2.96424514e+03  2.89453560e+03\n",
      " -9.90412670e+02 -9.35033331e+02 -1.50677358e+02 -2.31625809e+03\n",
      "  1.62381571e+03  1.03709295e+02  0.00000000e+00  1.03698289e+03\n",
      " -1.57668316e+03 -6.48336693e+02  5.06863059e+03 -1.27275196e+03\n",
      " -2.08532558e+03  1.67515223e+03  3.17823699e+02 -1.96189929e+03\n",
      "  0.00000000e+00 -2.60537919e+03 -2.07115882e+03 -0.00000000e+00\n",
      " -1.51382880e+03 -2.78835199e+03 -2.68610951e+01 -1.75453055e+03\n",
      " -3.44051040e+03  8.00189060e+03 -2.47701437e+03 -3.26038524e+03\n",
      "  8.39399035e+03 -3.26397184e+03 -4.26388765e+03 -4.09661649e+03\n",
      "  1.39222253e+03  4.42419948e+04  1.44811209e+04]\n",
      "Biais (intercept) : [17026.37244199]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victorien/.local/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.118e+10, tolerance: 1.083e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Création du modèle Lasso\n",
    "alpha_value = 0.1  # Force de la régularisation\n",
    "lasso_model = Lasso(alpha=alpha_value)\n",
    "\n",
    "# Entraînement du modèle\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "\n",
    "# Affichage des coefficients\n",
    "print(\"Coefficients du modèle :\", lasso_model.coef_)\n",
    "print(\"Biais (intercept) :\", lasso_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE): 32.64937675149142\n"
     ]
    }
   ],
   "source": [
    "# Calcul du Mean Absolute Percentage Error (MAPE)\n",
    "mape = np.mean(np.abs((np.array(y_test) - y_pred) / np.array(y_test)).flatten()) * 100\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
